{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOPHSXKavDscWpAimz2o1HK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","import os\n","from google.colab import drive\n","from collections import Counter\n","import re\n","import nltk # Mantenemos la importación de NLTK para la descarga, por si acaso\n","\n","# --- DESCARGA Y CONFIGURACIÓN ---\n","\n","# Forzar la descarga de stopwords (para reducir la chance de error)\n","try:\n","    nltk.download('stopwords', quiet=True)\n","except Exception:\n","    pass # Ignoramos el error si falla, porque usaremos la lista codificada\n","\n","# Lista de stopwords en español (Solución robusta contra LookupError)\n","try:\n","    # Intenta cargar la lista de NLTK\n","    stop_words_es = set(nltk.corpus.stopwords.words('spanish'))\n","except LookupError:\n","    # Si falla, usa la lista codificada\n","    print(\"ADVERTENCIA: Usando lista de stopwords codificada para asegurar la ejecución.\")\n","    stop_words_es = {'un', 'una', 'unas', 'unos', 'uno', 'sobre', 'también', 'tras', 'otro', 'otras', 'otros', 'otra', 'de', 'la', 'lo', 'las', 'los', 'a', 'ante', 'bajo', 'cabe', 'con', 'contra', 'desde', 'durante', 'en', 'entre', 'hacia', 'hasta', 'mediante', 'para', 'por', 'según', 'sin', 'so', 'sobre', 'tras', 'o', 'u', 'el', 'al', 'del', 'mi', 'mis', 'tu', 'tus', 'su', 'sus', 'aquel', 'aquella', 'aquellos', 'aquellas', 'este', 'esta', 'estos', 'estas', 'es', 'sea', 'pero', 'mas', 'más', 'y', 'e', 'si', 'sino', 'sólo', 'solo', 'tal', 'vez', 'toda', 'todo', 'todos', 'todas', 'qué', 'cual', 'cuales', 'quien', 'quienes', 'yo', 'me', 'mi', 'mío', 'mía', 'míos', 'mías', 'tú', 'te', 'ti', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'él', 'ella', 'ello', 'nos', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vos', 'vosotros', 'vosotras', 'vuestro', 'vuestra', 'vuestros', 'vuestras'}\n","\n","\n","# Montar Google Drive\n","try:\n","    drive.mount('/content/drive')\n","except:\n","    print(\"Drive ya montado.\")\n","\n","# Ruta a la carpeta que contiene tus archivos .txt\n","transcripciones_path = \"/content/drive/MyDrive/TFG_2025/Entrevistas/\"\n","\n","# Diccionario de conceptos clave para el TFG\n","conceptos_clave = {\n","    'Estrés_Ansiedad': ['estrés', 'ansiedad', 'nervioso', 'agobio', 'presión', 'malo', 'difícil'],\n","    'Recuperación_Calma': ['calma', 'relajación', 'tranquilidad', 'paz', 'descanso', 'mejor'],\n","    'Metacognición_Reflexión': ['sentir', 'pensar', 'darse', 'cuenta', 'conciencia', 'reflejar', 'mente', 'proceso'],\n","    'Intervención_Sonido': ['sonido', 'música', 'paisaje', 'audio'],\n","}\n","\n","\n","def clean_and_tokenize(text):\n","    # Usamos REGEX para tokenizar (soluciona el LookupError de Punkt)\n","    tokens = re.findall(r'[a-zA-ZáéíóúüñÁÉÍÓÚÜÑ]+', text.lower())\n","    # Limpieza: eliminar stopwords y palabras irrelevantes\n","    tokens = [word for word in tokens if word not in stop_words_es]\n","    tokens = [word for word in tokens if word not in ('gracias', 'sí', 'no', 'vale', 'entonces', 'pues', 'claro', 'eh', 'e', 'o')]\n","    return tokens\n","\n","# 1. Crear el DataFrame de conteo por participante\n","df_conteo = []\n","\n","for filename in os.listdir(transcripciones_path):\n","    if filename.endswith(\".txt\"):\n","        ruta_archivo = os.path.join(transcripciones_path, filename)\n","\n","        with open(ruta_archivo, 'r', encoding='utf-8') as f:\n","            content = f.read()\n","\n","        tokens = clean_and_tokenize(content)\n","        word_counts = Counter(tokens)\n","\n","        # Obtener el ID del participante (basado en el nombre del archivo)\n","        participante_data = {'ID_Participante': filename.split('.')[0]}\n","\n","        # Contar la frecuencia de cada concepto en esta entrevista\n","        for concepto, palabras in conceptos_clave.items():\n","            count = sum(word_counts[palabra] for palabra in palabras)\n","            participante_data[concepto] = count\n","\n","        df_conteo.append(participante_data)\n","\n","df_qualitativo = pd.DataFrame(df_conteo)\n","\n","# Guardar el Dataframe de conteo en Drive\n","output_path_qual = \"/content/drive/MyDrive/TFG_2025/Conteo_Conceptos_Participante.csv\"\n","df_qualitativo.to_csv(output_path_qual, index=False)\n","\n","print(\"\\n--- BASE DE DATOS CUALITATIVA CREADA ---\")\n","print(f\"DataFrame guardado en: {output_path_qual}\")\n","print(df_qualitativo)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z46v4ZSnHWRs","executionInfo":{"status":"ok","timestamp":1761324403912,"user_tz":180,"elapsed":6781,"user":{"displayName":"David Clausell","userId":"08477535265954107538"}},"outputId":"48a65e2b-097c-4e90-f2fb-f56a076dfeeb"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","\n","--- BASE DE DATOS CUALITATIVA CREADA ---\n","DataFrame guardado en: /content/drive/MyDrive/TFG_2025/Conteo_Conceptos_Participante.csv\n","   ID_Participante  Estrés_Ansiedad  Recuperación_Calma  \\\n","0    ale2311092025                2                   3   \n","1    rue1022092025                2                   2   \n","2    lli2108092025                5                   7   \n","3    ben2004092025                8                   7   \n","4    any0828082025                5                   4   \n","5    vas2804092025                9                   6   \n","6    yes1904092025                6                   8   \n","7    asi1621082025                2                   7   \n","8    bio0921082025                2                   6   \n","9    ESI0821082025                8                   6   \n","10   uro1628082025                5                   4   \n","11   osa1111092025                6                   4   \n","12   nto0828082025                4                   3   \n","13   eva1308092025                4                   9   \n","14   mez1402102025                3                   6   \n","15   rez1122092025                6                   9   \n","16   ino0821082025                7                  11   \n","\n","    Metacognición_Reflexión  Intervención_Sonido  \n","0                         1                    1  \n","1                         3                    2  \n","2                         0                    0  \n","3                         3                    1  \n","4                         0                    4  \n","5                         4                    6  \n","6                         4                    2  \n","7                         1                    5  \n","8                         6                    0  \n","9                         3                    0  \n","10                        3                    1  \n","11                        4                    4  \n","12                        4                    1  \n","13                       10                    0  \n","14                        0                    1  \n","15                       12                    0  \n","16                       10                   12  \n"]}]}]}